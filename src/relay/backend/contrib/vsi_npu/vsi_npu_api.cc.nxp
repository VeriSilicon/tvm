#include "vsi_npu_api.h"

namespace tvm {
namespace relay {
namespace contrib {
namespace vsi_npu {

// std::vector<std::string> RegisterOperationNameTable = {"qnn.add","add"};

// bool VsiNpuAPI::IsVsiNpuOp(const Call& call) {
//   if (call->op->IsInstance<OpNode>()) {
//     Op op = Downcast<Op>(call->op);
//     CHECK(op.defined());
//     for(auto RegisterOperationName: RegisterOperationNameTable){
//       if(op == Op::Get(RegisterOperationName)){
//         return true;
//       }
//     }
//   } else {
//     return false;
//   }
// }
VsiError VsiNpuAPI::Relu(const Expr& expr, TensorInfoTable& ti_tb,tim::vx::Quantization& quant_info){
  Call call = Downcast<Call>(expr);
  constexpr uint32_t input_idx = 0;
  assert(!call->args[input_idx]->IsInstance<ConstantNode>());
  tim::vx::ShapeType input_shape;

  std::transform(call->args[input_idx]->checked_type().as<TensorTypeNode>()->shape.begin(),
                 call->args[input_idx]->checked_type().as<TensorTypeNode>()->shape.end(),
                 std::back_inserter(input_shape),
                 [](const PrimExpr& dim) { return static_cast<int>(dim.as<IntImmNode>()->value); });

  if(call->args[input_idx]->checked_type().as<TensorTypeNode>()->dtype.is_float()){
    ti_tb[call->args[input_idx]] = {
      tvx::TensorSpec(tvx::DataType::FLOAT32, input_shape, tvx::TensorAttribute::TRANSIENT)};
  }else if(call->args[input_idx]->checked_type().as<TensorTypeNode>()->dtype.is_uint()){
    ti_tb[call->args[input_idx]] = {
      tvx::TensorSpec(tvx::DataType::UINT8, input_shape, tvx::TensorAttribute::TRANSIENT)};
  }

  return VsiError();   
}

VsiError VsiNpuAPI::Softmax(const Expr& expr, TensorInfoTable& ti_tb,tim::vx::Quantization& quant_info){
  Call call = Downcast<Call>(expr);
  constexpr uint32_t input_idx = 0;
  assert(!call->args[input_idx]->IsInstance<ConstantNode>());
  tim::vx::ShapeType input_shape;

  std::transform(call->args[input_idx]->checked_type().as<TensorTypeNode>()->shape.begin(),
                 call->args[input_idx]->checked_type().as<TensorTypeNode>()->shape.end(),
                 std::back_inserter(input_shape),
                 [](const PrimExpr& dim) { return static_cast<int>(dim.as<IntImmNode>()->value); });

  if(call->args[input_idx]->checked_type().as<TensorTypeNode>()->dtype.is_float()){
    ti_tb[call->args[input_idx]] = {
      tvx::TensorSpec(tvx::DataType::FLOAT32, input_shape, tvx::TensorAttribute::TRANSIENT)};
  }else if(call->args[input_idx]->checked_type().as<TensorTypeNode>()->dtype.is_uint()){
    ti_tb[call->args[input_idx]] = {
      tvx::TensorSpec(tvx::DataType::UINT8, input_shape, tvx::TensorAttribute::TRANSIENT)};
  }

  return VsiError();   
}

VsiError VsiNpuAPI::Addition(const Expr& expr, TensorInfoTable& ti_tb){
  Call call = Downcast<Call>(expr);

  constexpr uint32_t kInput_0_idx = 0;
  constexpr uint32_t kInput_1_idx = 1;

  assert(!call->args[kInput_0_idx]->IsInstance<ConstantNode>());
  assert(!call->args[kInput_1_idx]->IsInstance<ConstantNode>());

  tim::vx::ShapeType i0_shape, i1_shape;

  std::transform(call->args[kInput_0_idx]->checked_type().as<TensorTypeNode>()->shape.begin(),
                 call->args[kInput_0_idx]->checked_type().as<TensorTypeNode>()->shape.end(),
                 std::back_inserter(i0_shape),
                 [](const PrimExpr& dim) { return static_cast<int>(dim.as<IntImmNode>()->value); });
  std::transform(call->args[kInput_1_idx]->checked_type().as<TensorTypeNode>()->shape.begin(),
                 call->args[kInput_1_idx]->checked_type().as<TensorTypeNode>()->shape.end(),
                 std::back_inserter(i1_shape), [](const PrimExpr& dim) {
                   return static_cast<uint32_t>(dim.as<IntImmNode>()->value);
                 });

  // Set all tensor as transient here, we can modify the attribute when seting model input
  ti_tb[call->args[kInput_0_idx]] = {
      tvx::TensorSpec(tvx::DataType::FLOAT32, i0_shape, tvx::TensorAttribute::TRANSIENT)};
  ti_tb[call->args[kInput_1_idx]] = {
      tvx::TensorSpec(tvx::DataType::FLOAT32, i1_shape, tvx::TensorAttribute::TRANSIENT)};
  //quant_info.SetType(tvx::QuantType::ASYMMETRIC).SetScales({out_scale}).SetZeroPoints({out_zp});
  return VsiError();

}

VsiError VsiNpuAPI::Addition(const Expr& expr, TensorInfoTable& ti_tb,
                             tim::vx::Quantization& quant_info) {
  Call call = Downcast<Call>(expr);
  // qnn.add arguments
  constexpr uint32_t kInput_0_idx = 0;
  constexpr uint32_t kInput_1_idx = 1;
  constexpr uint32_t kInput_0_scale_idx = 2;
  constexpr uint32_t kInput_0_zp_Idx = 3;
  constexpr uint32_t kInput_1_scale_idx = 4;
  constexpr uint32_t kInput_1_zp_idx = 5;

  constexpr uint32_t kOutput_scale_idx = 6;
  constexpr uint32_t kOutput_zp_idx = 7;

  assert(call->args[kInput_0_scale_idx]->IsInstance<ConstantNode>());
  assert(call->args[kInput_0_zp_Idx]->IsInstance<ConstantNode>());
  assert(call->args[kInput_1_scale_idx]->IsInstance<ConstantNode>());
  assert(call->args[kInput_1_zp_idx]->IsInstance<ConstantNode>());
  assert(call->args[kOutput_scale_idx]->IsInstance<ConstantNode>());
  assert(call->args[kOutput_zp_idx]->IsInstance<ConstantNode>());

  float i0_scale;
  int i0_zp;
  float i1_scale;
  int i1_zp;
  float out_scale;
  int out_zp;

  bool data_access_success = AsConstant<float>(call->args[kInput_0_scale_idx], &i0_scale) &&
                             AsConstant<int>(call->args[kInput_0_zp_Idx], &i0_zp) &&
                             AsConstant<float>(call->args[kInput_1_scale_idx], &i1_scale) &&
                             AsConstant<int>(call->args[kInput_1_zp_idx], &i1_zp) &&
                             AsConstant<float>(call->args[kOutput_scale_idx], &out_scale) &&
                             AsConstant<int>(call->args[kOutput_zp_idx], &out_zp);
  if(!data_access_success){
    return VsiError();
  }
  tim::vx::ShapeType i0_shape, i1_shape;

  assert(!call->args[kInput_0_idx]->IsInstance<ConstantNode>());
  assert(!call->args[kInput_1_idx]->IsInstance<ConstantNode>());

  std::transform(call->args[kInput_0_idx]->checked_type().as<TensorTypeNode>()->shape.begin(),
                 call->args[kInput_0_idx]->checked_type().as<TensorTypeNode>()->shape.end(),
                 std::back_inserter(i0_shape),
                 [](const PrimExpr& dim) { return static_cast<int>(dim.as<IntImmNode>()->value); });
  std::transform(call->args[kInput_1_idx]->checked_type().as<TensorTypeNode>()->shape.begin(),
                 call->args[kInput_1_idx]->checked_type().as<TensorTypeNode>()->shape.end(),
                 std::back_inserter(i1_shape), [](const PrimExpr& dim) {
                   return static_cast<uint32_t>(dim.as<IntImmNode>()->value);
                 });
  tvx::Quantization i0_quant(tvx::QuantType::ASYMMETRIC, i0_scale, i0_zp);
  tvx::Quantization i1_quant(tvx::QuantType::ASYMMETRIC, i1_scale, i1_zp);
  // Set all tensor as transient here, we can modify the attribute when seting model input
  ti_tb[call->args[kInput_0_idx]] = {
      tvx::TensorSpec(tvx::DataType::UINT8, i0_shape, tvx::TensorAttribute::TRANSIENT)
          .SetQuantization(i0_quant)};
  ti_tb[call->args[kInput_1_idx]] = {
      tvx::TensorSpec(tvx::DataType::UINT8, i1_shape, tvx::TensorAttribute::TRANSIENT)
          .SetQuantization(i1_quant)};
  quant_info.SetType(tvx::QuantType::ASYMMETRIC).SetScales({out_scale}).SetZeroPoints({out_zp});
  return VsiError();
}
}  // namespace vsi_npu
}  // namespace contrib
}  // namespace relay
}  // namespace tvm